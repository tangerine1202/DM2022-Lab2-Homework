{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: ÈªÉ‰øäÁëã \n",
    "\n",
    "Student ID: 108062308\n",
    "\n",
    "GitHub ID: [tangerine1202](https://github.com/tangerine1202/DM2022-Lab2-Homework)\n",
    "\n",
    "Kaggle name: [Chun Wei Huang](https://www.kaggle.com/tangerine1202)\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "![rank 3rd in private leaderboard](img/pic0.png)\n",
    "*rank 3rd in private leaderboard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by [this link](https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd). The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "\n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the img folder of this repository and rerun the cell Student Information.\n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Part: Take Home Exercises\n",
    "\n",
    "- repo link: https://github.com/tangerine1202/DM2022-Lab2-Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Part: Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice: two separated report files\n",
    "\n",
    "- For clarity, I separated codes into two part, \"EDA & data preprocessing\" and \"training & inference\". \n",
    "\n",
    "- This notebook is about the \"training & inference\" part. It directly loaded the preprocessed data from the \"EDA & data preprocessing\" part.\n",
    "\n",
    "- For more details about EDA and data preprocessing, please refer to another notebook file at [\"./EDA.ipynb\"](./EDA.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since training a NLU model requires a lot of resource, it's better to used a pre-trained model. I used the pre-trained model [cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) from [HuggingFace](https://huggingface.co/transformers/pretrained_models.html) to fine-tune the model, because this model is pre-trained on Twitter sentiment analysis dataset which is similar to our task. Then, I implemented a custom model to be able to concatenate the external features with the pre-trained model at the last dense layer, see [Custom Model](#Custom-Model).\n",
    "\n",
    "For my best submission, however, I only used the slightly modified tweet text (see below for details) as only input. I believe that the external features can be helpful to the performance and convergence speed. But it took 40+ hours for the model with only text data to converge. The training time/cost is to huge and the performance of this model already good enough for me, so I decided not to try again with the external features.\n",
    "\n",
    "\n",
    "*slightly modified tweet text*\n",
    "- removed \"\\<LH\\>\" in the text\n",
    "- replaced the user mention with \"@user\" if the times of the user mention is less than 5\n",
    "\n",
    "*change custom model to concatenate external features*\n",
    "- uncomment `INPUT_COLUMNS` in [Hyper-parameters](#Hyper-parameters)\n",
    "- uncomment few lines in `CustomModel` in [Custom Model](#Custom-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The hyper-parameters used by the best submission are the same as this notebook shown.)\n",
    "\n",
    "(The output of this notebook is demo with 100 data samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:55:04.909365: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 18:55:05.070658: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-26 18:55:05.593939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-26 18:55:05.594081: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-26 18:55:05.594090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from datasets import Dataset, load_dataset\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import get_scheduler\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "TRAIN_DATA_PATH = 'data/train_data.pkl'\n",
    "TRAIN_LABEL_PATH = 'data/train_labels.pkl'\n",
    "TEST_DATA_PATH = 'data/test_data.pkl'\n",
    "CHECKPOINTS_PATH = 'checkpoints/'\n",
    "TEXT_COL_NAME = 'replace_user_text'\n",
    "EMOTION_NAMES = ['joy', 'anticipation', 'trust' , 'sadness' , 'disgust' , 'fear' , 'surprise', 'anger']\n",
    "INPUT_COLUMNS = [TEXT_COL_NAME, 'label'] #, *[f'{emo}_ratio' for emo in EMOTION_NAMES]]\n",
    "\n",
    "# constants\n",
    "MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "NUM_LABELS = 8\n",
    "CHECKPOINTS_SIZE = 500\n",
    "\n",
    "# model & training \n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-5\n",
    "LR_WARMUP_RATIO = 0.01\n",
    "TRAIN_SIZE = 145_0000 # total 145_5563\n",
    "EVAL_SIZE = 2225\n",
    "TEST_SIZE = 3338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion2id = {emotion: i for i, emotion in enumerate(EMOTION_NAMES)}\n",
    "id2emotion = {i: emotion for i, emotion in enumerate(EMOTION_NAMES)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>lower_tags</th>\n",
       "      <th>joy_ratio</th>\n",
       "      <th>anticipation_ratio</th>\n",
       "      <th>trust_ratio</th>\n",
       "      <th>sadness_ratio</th>\n",
       "      <th>disgust_ratio</th>\n",
       "      <th>fear_ratio</th>\n",
       "      <th>surprise_ratio</th>\n",
       "      <th>anger_ratio</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>replace_user_text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x34b02b</th>\n",
       "      <td>682</td>\n",
       "      <td>2015-09-15 06:21:50</td>\n",
       "      <td>[PayAttention, StayWoke]</td>\n",
       "      <td>@funder @jeffgoldesq Mere &lt;LH&gt; ...sh*t's about...</td>\n",
       "      <td>[#payattention, #staywoke]</td>\n",
       "      <td>0.331984</td>\n",
       "      <td>0.186235</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.178138</td>\n",
       "      <td>0.072874</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>0.032389</td>\n",
       "      <td>[funder, jeffgoldesq]</td>\n",
       "      <td>@funder @user Mere  ...sh*t's about to hit the...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2ab860</th>\n",
       "      <td>836</td>\n",
       "      <td>2016-02-24 11:09:26</td>\n",
       "      <td>[WordPlay, beautiful]</td>\n",
       "      <td>#WordPlay helps turn something hateful into so...</td>\n",
       "      <td>[#wordplay, #beautiful]</td>\n",
       "      <td>0.962721</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>[]</td>\n",
       "      <td>#WordPlay helps turn something hateful into so...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x23a81a</th>\n",
       "      <td>145</td>\n",
       "      <td>2016-01-20 08:02:20</td>\n",
       "      <td>[YouTuber]</td>\n",
       "      <td>a big shout out to anyone who is either like c...</td>\n",
       "      <td>[#youtuber]</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.044218</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>[]</td>\n",
       "      <td>a big shout out to anyone who is either like c...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x24cbd2</th>\n",
       "      <td>790</td>\n",
       "      <td>2017-02-04 12:09:20</td>\n",
       "      <td>[RickPitino, FBI, NCAABribery]</td>\n",
       "      <td>Anyone that believes #RickPitino knew nothing ...</td>\n",
       "      <td>[#rickpitino, #fbi, #ncaabribery]</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.149123</td>\n",
       "      <td>0.307018</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>[]</td>\n",
       "      <td>Anyone that believes #RickPitino knew nothing ...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x3142a3</th>\n",
       "      <td>182</td>\n",
       "      <td>2017-01-06 23:24:39</td>\n",
       "      <td>[blessings]</td>\n",
       "      <td>Typos can't count on that üôèüèΩ &lt;LH&gt; #blessings</td>\n",
       "      <td>[#blessings]</td>\n",
       "      <td>0.456048</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.262960</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>[]</td>\n",
       "      <td>Typos can't count on that üôèüèΩ  #blessings</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _score           _crawldate                        hashtags  \\\n",
       "tweet_id                                                                \n",
       "0x34b02b     682  2015-09-15 06:21:50        [PayAttention, StayWoke]   \n",
       "0x2ab860     836  2016-02-24 11:09:26           [WordPlay, beautiful]   \n",
       "0x23a81a     145  2016-01-20 08:02:20                      [YouTuber]   \n",
       "0x24cbd2     790  2017-02-04 12:09:20  [RickPitino, FBI, NCAABribery]   \n",
       "0x3142a3     182  2017-01-06 23:24:39                     [blessings]   \n",
       "\n",
       "                                                       text  \\\n",
       "tweet_id                                                      \n",
       "0x34b02b  @funder @jeffgoldesq Mere <LH> ...sh*t's about...   \n",
       "0x2ab860  #WordPlay helps turn something hateful into so...   \n",
       "0x23a81a  a big shout out to anyone who is either like c...   \n",
       "0x24cbd2  Anyone that believes #RickPitino knew nothing ...   \n",
       "0x3142a3       Typos can't count on that üôèüèΩ <LH> #blessings   \n",
       "\n",
       "                                 lower_tags  joy_ratio  anticipation_ratio  \\\n",
       "tweet_id                                                                     \n",
       "0x34b02b         [#payattention, #staywoke]   0.331984            0.186235   \n",
       "0x2ab860            [#wordplay, #beautiful]   0.962721            0.005232   \n",
       "0x23a81a                        [#youtuber]   0.537415            0.170068   \n",
       "0x24cbd2  [#rickpitino, #fbi, #ncaabribery]   0.070175            0.122807   \n",
       "0x3142a3                       [#blessings]   0.456048            0.264463   \n",
       "\n",
       "          trust_ratio  sadness_ratio  disgust_ratio  fear_ratio  \\\n",
       "tweet_id                                                          \n",
       "0x34b02b     0.076923       0.178138       0.072874    0.036437   \n",
       "0x2ab860     0.015043       0.002616       0.009810    0.001962   \n",
       "0x23a81a     0.115646       0.061224       0.044218    0.013605   \n",
       "0x24cbd2     0.149123       0.307018       0.166667    0.052632   \n",
       "0x3142a3     0.262960       0.005259       0.001503    0.003757   \n",
       "\n",
       "          surprise_ratio  anger_ratio          user_mentions  \\\n",
       "tweet_id                                                       \n",
       "0x34b02b        0.085020     0.032389  [funder, jeffgoldesq]   \n",
       "0x2ab860        0.001308     0.001308                     []   \n",
       "0x23a81a        0.040816     0.017007                     []   \n",
       "0x24cbd2        0.078947     0.052632                     []   \n",
       "0x3142a3        0.004508     0.001503                     []   \n",
       "\n",
       "                                          replace_user_text       emotion  \\\n",
       "tweet_id                                                                    \n",
       "0x34b02b  @funder @user Mere  ...sh*t's about to hit the...      surprise   \n",
       "0x2ab860  #WordPlay helps turn something hateful into so...           joy   \n",
       "0x23a81a  a big shout out to anyone who is either like c...           joy   \n",
       "0x24cbd2  Anyone that believes #RickPitino knew nothing ...  anticipation   \n",
       "0x3142a3           Typos can't count on that üôèüèΩ  #blessings  anticipation   \n",
       "\n",
       "          label  \n",
       "tweet_id         \n",
       "0x34b02b      6  \n",
       "0x2ab860      0  \n",
       "0x23a81a      0  \n",
       "0x24cbd2      1  \n",
       "0x3142a3      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_X = pd.read_pickle(TRAIN_DATA_PATH)\n",
    "df_train_y = pd.read_pickle(TRAIN_LABEL_PATH)\n",
    "assert len(df_train_X) == len(df_train_y)\n",
    "df_train = pd.concat([df_train_X, df_train_y], axis=1)\n",
    "\n",
    "# numerical labels\n",
    "df_train['label'] = df_train['emotion'].map(lambda x: emotion2id[x])\n",
    "\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[TEXT_COL_NAME], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['replace_user_text', 'label', 'tweet_id'],\n",
       "    num_rows: 1455563\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df_train[INPUT_COLUMNS])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4015d488bbf48bdb6f57d70a9890466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text column\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "# saved the tokenized datasets, so we don't need to tokenize again if we do not change the text column\n",
    "tokenized_datasets.save_to_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenized datasets\n",
    "tokenized_datasets = Dataset.load_from_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to the hugging face format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1455563\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process dataset features to fit the requirement of the hugging face model\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([TEXT_COL_NAME, 'tweet_id'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at data/cardiffnlp/twitter-roberta-base-sentiment-latest_tokenized_datasets/cache-264420d4d8242261.arrow\n",
      "Loading cached shuffled indices for dataset at data/cardiffnlp/twitter-roberta-base-sentiment-latest_tokenized_datasets/cache-264420d4d8242261.arrow\n",
      "Loading cached shuffled indices for dataset at data/cardiffnlp/twitter-roberta-base-sentiment-latest_tokenized_datasets/cache-264420d4d8242261.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:\t100\t0.007%\n",
      "eval     size:\t100\t0.007%\n",
      "test     size:\t100\t0.007%\n"
     ]
    }
   ],
   "source": [
    "# split the dataset\n",
    "small_train_dataset = tokenized_datasets.shuffle(seed=42).select(range(TRAIN_SIZE))\n",
    "small_eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(TRAIN_SIZE, TRAIN_SIZE + EVAL_SIZE))\n",
    "test_dataset = tokenized_datasets.shuffle(seed=42).select(range(TRAIN_SIZE + EVAL_SIZE, TRAIN_SIZE + EVAL_SIZE + TEST_SIZE))\n",
    "# NOTE: do not shuffle the training set in dataloader again, in order to keep the same shuffle random seed\n",
    "train_dataloader = DataLoader(small_train_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "\n",
    "print(f'training size:\\t{len(small_train_dataset)}\\t{len(small_train_dataset) / 1455563 * 100 :.3f}%')\n",
    "print(f'eval     size:\\t{len(small_eval_dataset)}\\t{len(small_eval_dataset) / 1455563 * 100 :.3f}%')\n",
    "print(f'test     size:\\t{len(test_dataset)}\\t{len(test_dataset) / 1455563 * 100 :.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model\n",
    "\n",
    "- combining external feature to the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom model to *combine the external features* into the hugging face model\n",
    "# ref: https://towardsdatascience.com/adding-custom-layers-on-top-of-a-hugging-face-model-f1ccdfc257bd\n",
    "class CustomModel(torch.nn.Module):\n",
    "  def __init__(self, checkpoint, num_labels): \n",
    "    super(CustomModel,self).__init__() \n",
    "    self.num_labels = num_labels \n",
    "\n",
    "    # Load Model with given checkpoint and extract its body\n",
    "    self.model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
    "    self.seq_dropout = torch.nn.Dropout(0.3) \n",
    "    # self.features_dropout = torch.nn.Dropout(0.0)\n",
    "    # self.classifier = torch.nn.Linear(768 + NUM_LABELS, num_labels) # load and initialize weights\n",
    "    self.classifier = torch.nn.Linear(768, num_labels) # load and initialize weights\n",
    "\n",
    "  def forward(self, \n",
    "    input_ids=None, attention_mask=None, labels=None,\n",
    "    # joy_ratio=None, anticipation_ratio=None, trust_ratio=None, sadness_ratio=None, disgust_ratio=None, fear_ratio=None, surprise_ratio=None, anger_ratio=None\n",
    "  ):\n",
    "    # Extract outputs from the body\n",
    "    # pretrained_outputs[0]=last hidden state\n",
    "    pretrained_outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    seq_outputs = self.seq_dropout(pretrained_outputs[0])[:, 0, :].view(-1, 768) # seq shape torch.Size([16, 768])\n",
    "\n",
    "    # Add emotion ratios\n",
    "    # emo_ratio_outputs = torch.stack([joy_ratio, anticipation_ratio, trust_ratio, sadness_ratio, disgust_ratio, fear_ratio, surprise_ratio, anger_ratio], dim=1)\n",
    "    # features_outputs = self.features_dropout(emo_ratio_outputs) # emo_ratio shape torch.Size([16, 8])\n",
    "\n",
    "    # Concatenate\n",
    "    # outputs = torch.cat((seq_outputs, features_outputs), dim=1)\n",
    "    outputs = seq_outputs\n",
    "    logits = self.classifier(outputs) # calculate losses\n",
    "    \n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "      loss_fct = torch.nn.CrossEntropyLoss()\n",
    "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    \n",
    "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=pretrained_outputs.hidden_states ,attentions=pretrained_outputs.attentions)\n",
    "  \n",
    "  def save_checkpoint(self, steps):\n",
    "    torch.save(self.state_dict(), f'{CHECKPOINTS_PATH}{steps}.pt')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiate new model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (seq_dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model\n",
    "if os.path.isfile(f'model/{MODEL_NAME}-custom-{TRAIN_SIZE}') and input('Use pre-trained model? (y/n)') == 'y':\n",
    "  model = torch.load(f'model/{MODEL_NAME}-custom-{TRAIN_SIZE}')\n",
    "  print('Using pre-trained model')\n",
    "else:\n",
    "  model = CustomModel(MODEL_NAME, NUM_LABELS)\n",
    "  print('Instantiate new model')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n",
    "\n",
    "# linear learning rate scheduler with warmup\n",
    "num_training_steps = EPOCHS * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=int(num_training_steps*LR_WARMUP_RATIO), num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metric = evaluate.load(\"f1\")\n",
    "acu_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics():\n",
    "    f1_macro = f1_metric.compute(average='macro')['f1']\n",
    "    acu = acu_metric.compute()['accuracy']\n",
    "    return {'f1_macro': f1_macro, 'acu': acu}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "device = accelerator.device\n",
    "model.to(device)\n",
    "\n",
    "model, optimizer, train_dataloader, lr_scheduler, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, lr_scheduler, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7ce649addf46d8a2ab5a8eb9967060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5434dc4516453bae957ebc2f115cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(int(num_training_steps / CHECKPOINTS_SIZE) * len(eval_dataloader)))\n",
    "\n",
    "best_f1 = 0\n",
    "early_stop_cnt = 0\n",
    "steps = 0\n",
    "cumulative_loss = 0\n",
    "for epoch in range(EPOCHS):\n",
    "  model.train()\n",
    "  for batch in train_dataloader:\n",
    "      optimizer.zero_grad()\n",
    "      # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "      batch = {k: v for k, v in batch.items()}  # accelerator\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      # loss.backward()\n",
    "      accelerator.backward(loss)  # accelerator\n",
    "      \n",
    "      optimizer.step()\n",
    "      lr_scheduler.step()\n",
    "      progress_bar_train.update(1)\n",
    "\n",
    "      cumulative_loss += loss.item()\n",
    "      steps += 1\n",
    "\n",
    "      if steps % CHECKPOINTS_SIZE == 0:\n",
    "        print(f'step {steps} training loss: {cumulative_loss / CHECKPOINTS_SIZE}')\n",
    "        cumulative_loss = 0\n",
    "        model.save_checkpoint(steps)\n",
    "\n",
    "        model.eval()\n",
    "        for batch in eval_dataloader:\n",
    "          # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "          batch = {k: v for k, v in batch.items()}  # accelerator\n",
    "          with torch.no_grad():\n",
    "              outputs = model(**batch)\n",
    "\n",
    "          logits = outputs.logits\n",
    "          predictions = torch.argmax(logits, dim=-1)\n",
    "          f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "          acu_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "          progress_bar_eval.update(1)\n",
    "          \n",
    "        metrics = compute_metrics()\n",
    "        print(metrics)\n",
    "\n",
    "        # early stop when f1 score drop significantly\n",
    "        if metrics['f1_macro'] < (best_f1 - 0.1):\n",
    "          early_stop_cnt += 1\n",
    "          print(f'early stop cnt = {early_stop_cnt}')\n",
    "          if early_stop_cnt >= 3:\n",
    "            print('Early stop')\n",
    "            break\n",
    "\n",
    "        best_f1 = max(best_f1, metrics['f1_macro'])\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to model/20221126-185821\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "saved_path = f'model/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "torch.save(model, saved_path)\n",
    "print(f'Saved model to {saved_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63267c766c6c4afbb460320c55d11b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.13203794369645042, 'acu': 0.47}\n"
     ]
    }
   ],
   "source": [
    "f1_metric = evaluate.load(\"f1\")\n",
    "acu_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "progress_bar_test = tqdm(range(len(test_dataloader)))\n",
    "\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    acu_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    progress_bar_test.update(1)\n",
    "\n",
    "print(compute_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model = CustomModel(MODEL_NAME, NUM_LABELS).to(device)\n",
    "# model.load_state_dict(torch.load(f'{CHECKPOINTS_PATH}{195000}.pt'))\n",
    "# model = torch.load(f'model/20221124-235147')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 40\n",
    "\n",
    "TEST_INPUT_COLUMNS = INPUT_COLUMNS.copy()\n",
    "if 'label' in TEST_INPUT_COLUMNS:\n",
    "  TEST_INPUT_COLUMNS.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replace_user_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x1fadea</th>\n",
       "      <td>So @Qantas says it's @user @user fault that no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1e64e4</th>\n",
       "      <td>The great thing about faith in God is that it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x353889</th>\n",
       "      <td>@eucopresident Donald Tusk, @EU_Commission Jea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2d4320</th>\n",
       "      <td>Maybe the Wall was the friends we made along t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x231e50</th>\n",
       "      <td>@colin_w_ I specifically answered to get Ursul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          replace_user_text\n",
       "tweet_id                                                   \n",
       "0x1fadea  So @Qantas says it's @user @user fault that no...\n",
       "0x1e64e4  The great thing about faith in God is that it ...\n",
       "0x353889  @eucopresident Donald Tusk, @EU_Commission Jea...\n",
       "0x2d4320  Maybe the Wall was the friends we made along t...\n",
       "0x231e50  @colin_w_ I specifically answered to get Ursul..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_pickle(TEST_DATA_PATH)\n",
    "df_test = df_test[TEST_INPUT_COLUMNS]\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff168beb3b647f4a389a91f92368a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 411972\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(df_test[TEST_INPUT_COLUMNS])\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.remove_columns([TEXT_COL_NAME, 'tweet_id'])\n",
    "test_dataset.set_format(type='torch')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ec3d438bbb49efa6e1d9e8ff28ac00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m---> 10\u001b[0m     batch \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m         outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n",
      "Cell \u001b[0;32mIn [25], line 10\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m---> 10\u001b[0m     batch \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m         outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'id': df_test.index})\n",
    "df_result['label'] = np.zeros(len(df_result)) - 1\n",
    "gpu_tensor = torch.tensor(df_result['label'].values, dtype=torch.long, device=device)\n",
    "\n",
    "progress_bar_test = tqdm(range(len(test_dataloader)))\n",
    "\n",
    "idx = 0\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    gpu_tensor[idx:idx+len(predictions)] = predictions\n",
    "    idx += len(predictions)\n",
    "    progress_bar_test.update(1)\n",
    "\n",
    "df_result['label'] = gpu_tensor.cpu().numpy()\n",
    "\n",
    "# convert label to emotion\n",
    "df_result['emotion'] = df_result['label'].map(lambda x: id2emotion[x])\n",
    "\n",
    "df_result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission/cardiffnlp/twitter-roberta-base-sentiment-latest-custom-20221119-234512.csv\n"
     ]
    }
   ],
   "source": [
    "saved_path = f'submission/{MODEL_NAME}-custom-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.csv'\n",
    "df_result[['id', 'emotion']].to_csv(saved_path, index=False)\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd18ad61a764f50ef87415555d6b20bbe826f43f65518458ad3ed025fdd4cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
