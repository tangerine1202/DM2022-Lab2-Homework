{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 黃俊瑋 \n",
    "\n",
    "Student ID: 108062308\n",
    "\n",
    "GitHub ID: [tangerine1202](https://github.com/tangerine1202/DM2022-Lab2-Homework)\n",
    "\n",
    "Kaggle name: [Chun Wei Huang](https://www.kaggle.com/tangerine1202)\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by [this link](https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd). The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "\n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the img folder of this repository and rerun the cell Student Information.\n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Part: Take Home Exercises\n",
    "\n",
    "- repo link: https://github.com/tangerine1202/DM2022-Lab2-Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Part: Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ident = pd.read_csv('data/data_identification.csv', index_col='tweet_id')\n",
    "labels = pd.read_csv('data/emotion.csv', index_col='tweet_id')\n",
    "\n",
    "print('train size', ident[ident['identification'] == 'train'].shape)\n",
    "print('test  size', ident[ident['identification'] == 'test'].shape)\n",
    "\n",
    "print(ident.head(3))\n",
    "print(labels.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = ident[ident['identification'] == 'train'].index\n",
    "train_labels = labels.loc[train_idxs, 'emotion']\n",
    "\n",
    "train_labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('labels distribution')\n",
    "print(train_labels.value_counts())\n",
    "sns.barplot(x=train_labels.value_counts().index, y=train_labels.value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data/tweets_DM.json', lines=True)\n",
    "\n",
    "# drop useless columns (only 1 unique value)\n",
    "data = data.drop(columns=['_index', '_type'])\n",
    "source = data['_source']\n",
    "\n",
    "# parsing tweet\n",
    "def parse_source(data):\n",
    "    data = data['tweet']\n",
    "    parsed_data = {}\n",
    "    for key, value in data.items():\n",
    "      parsed_data[key] = value\n",
    "    return parsed_data\n",
    "tweet = pd.DataFrame(source.map(parse_source).tolist())\n",
    "data = pd.concat([data, tweet], axis=1)\n",
    "data = data.drop(columns=['_source'])\n",
    "\n",
    "data.set_index('tweet_id', inplace=True)\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.loc[train_idxs, :].sort_values(by='tweet_id')\n",
    "test_data = data.loc[~data.index.isin(train_idxs), :].sort_values(by='tweet_id')\n",
    "train_labels = train_labels.sort_index()\n",
    "\n",
    "assert len(train_data) == len(train_labels)\n",
    "assert np.all(train_data.index == train_labels.index)\n",
    "print(len(data))\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle('data/train_data.pkl')\n",
    "train_labels.to_pickle('data/train_labels.pkl')\n",
    "test_data.to_pickle('data/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: lost some rows in training data when reading from tsv\n",
    "# train_data.to_csv('data/train_data.tsv', sep='\\t', encoding='utf-8')\n",
    "# train_labels.to_csv('data/train_labels.tsv', sep='\\t', encoding='utf-8')\n",
    "# test_data.to_csv('data/test_data.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What `_score` means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['_score'].describe())\n",
    "sns.histplot(data['_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning from Hugging Face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 01:53:11.208198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-15 01:53:11.351321: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-15 01:53:11.839147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-15 01:53:11.839304: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-15 01:53:11.839312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_metric\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import get_scheduler\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "TRAIN_DATA_PATH = 'data/train_data.pkl'\n",
    "TRAIN_LABEL_PATH = 'data/train_labels.pkl'\n",
    "TEST_DATA_PATH = 'data/test_data.pkl'\n",
    "EMOTION_NAMES = ['joy', 'anticipation', 'trust' , 'sadness' , 'disgust' , 'fear' , 'surprise', 'anger']\n",
    "\n",
    "# constants\n",
    "MODEL_NAME = 'bert-base-cased'\n",
    "NUM_LABELS = 8\n",
    "\n",
    "# hyper-parameters\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion2id = {emotion: i for i, emotion in enumerate(EMOTION_NAMES)}\n",
    "id2emotion = {i: emotion for i, emotion in enumerate(EMOTION_NAMES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_X = pd.read_pickle(TRAIN_DATA_PATH)\n",
    "df_train_y = pd.read_pickle(TRAIN_LABEL_PATH)\n",
    "assert len(df_train_X) == len(df_train_y)\n",
    "df_train = pd.concat([df_train_X, df_train_y], axis=1)\n",
    "\n",
    "# numerical labels\n",
    "df_train['label'] = df_train['emotion'].map(lambda x: emotion2id[x])\n",
    "\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_train[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets.save_to_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = Dataset.load_from_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_size = 50000\n",
    "small_eval_size = 10000\n",
    "small_train_dataset = tokenized_datasets.shuffle(seed=42).select(range(small_train_size))\n",
    "small_eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(small_train_size, small_train_size + small_eval_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\", \n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metric = evaluate.load(\"f1\")\n",
    "acu_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    f1_macro = f1_metric.compute(predictions=predictions, references=labels, average='macro')['f1']\n",
    "    acu = acu_metric.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    return {'f1_macro': f1_macro, 'acu': acu}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f'model/{MODEL_NAME}-50000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = pipeline(\n",
    "#     'sentiment-analysis', \n",
    "#     model=model, \n",
    "#     tokenizer=tokenizer,\n",
    "#     device=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf = pd.DataFrame(classifier(small_eval_dataset['text']))\n",
    "# tdf['answer'] = pd.DataFrame(small_eval_dataset['label'])\n",
    "# tdf['pred'] = tdf['label']\n",
    "# tdf.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf['results'] = tdf['pred'].map(lambda s: int(s[-1])) == tdf['answer']\n",
    "# tdf['results'] = tdf['results'].astype(float)\n",
    "# tdf['results'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle(TEST_DATA_PATH)\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    'sentiment-analysis', \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx = None\n",
    "\n",
    "# prediction\n",
    "df_result = pd.DataFrame(classifier(df_test['text'][:end_idx].tolist(), batch_size=TEST_BATCH_SIZE))\n",
    "# tweet_id as id\n",
    "df_result['id'] = df_test.index[:end_idx]\n",
    "# convert label to emotion\n",
    "df_result['emotion'] = df_result['label'].map(lambda s: id2emotion[int(s[-1])])\n",
    "\n",
    "df_result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[['tweet_id', 'emotion']].to_csv(f'submission/01.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "TRAIN_DATA_PATH = 'data/train_data.pkl'\n",
    "TRAIN_LABEL_PATH = 'data/train_labels.pkl'\n",
    "TEST_DATA_PATH = 'data/test_data.pkl'\n",
    "EMOTION_NAMES = ['joy', 'anticipation', 'trust' , 'sadness' , 'disgust' , 'fear' , 'surprise', 'anger']\n",
    "\n",
    "# constants\n",
    "MODEL_NAME = 'cardiffnlp/twitter-roberta-base-emotion'\n",
    "NUM_LABELS = 8\n",
    "\n",
    "# hyper-parameters\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "LR = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion2id = {emotion: i for i, emotion in enumerate(EMOTION_NAMES)}\n",
    "id2emotion = {i: emotion for i, emotion in enumerate(EMOTION_NAMES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x1e8497</th>\n",
       "      <td>362</td>\n",
       "      <td>2017-04-26 18:09:52</td>\n",
       "      <td>[Men, life, addiction, desire, attraction, ten...</td>\n",
       "      <td>#Men are too important in my #life. But what's...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2004b0</th>\n",
       "      <td>1020</td>\n",
       "      <td>2016-01-05 09:19:21</td>\n",
       "      <td>[inspiration]</td>\n",
       "      <td>Believe you can and you are halfway there. - T...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x28e8a0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-02 22:50:02</td>\n",
       "      <td>[buttrue]</td>\n",
       "      <td>I feel like with the current state of the affa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2f8cc0</th>\n",
       "      <td>548</td>\n",
       "      <td>2017-02-24 18:53:49</td>\n",
       "      <td>[]</td>\n",
       "      <td>Luke 13-5 I tell you, no; but unless you repen...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x31833a</th>\n",
       "      <td>123</td>\n",
       "      <td>2017-04-05 20:43:04</td>\n",
       "      <td>[property, management, condo, assessement]</td>\n",
       "      <td>@ellsavvy Has anyone heard of a #property #man...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _score           _crawldate  \\\n",
       "tweet_id                                \n",
       "0x1e8497     362  2017-04-26 18:09:52   \n",
       "0x2004b0    1020  2016-01-05 09:19:21   \n",
       "0x28e8a0       1  2015-05-02 22:50:02   \n",
       "0x2f8cc0     548  2017-02-24 18:53:49   \n",
       "0x31833a     123  2017-04-05 20:43:04   \n",
       "\n",
       "                                                   hashtags  \\\n",
       "tweet_id                                                      \n",
       "0x1e8497  [Men, life, addiction, desire, attraction, ten...   \n",
       "0x2004b0                                      [inspiration]   \n",
       "0x28e8a0                                          [buttrue]   \n",
       "0x2f8cc0                                                 []   \n",
       "0x31833a         [property, management, condo, assessement]   \n",
       "\n",
       "                                                       text       emotion  \\\n",
       "tweet_id                                                                    \n",
       "0x1e8497  #Men are too important in my #life. But what's...           joy   \n",
       "0x2004b0  Believe you can and you are halfway there. - T...  anticipation   \n",
       "0x28e8a0  I feel like with the current state of the affa...       sadness   \n",
       "0x2f8cc0  Luke 13-5 I tell you, no; but unless you repen...  anticipation   \n",
       "0x31833a  @ellsavvy Has anyone heard of a #property #man...           joy   \n",
       "\n",
       "          label  \n",
       "tweet_id         \n",
       "0x1e8497      0  \n",
       "0x2004b0      1  \n",
       "0x28e8a0      3  \n",
       "0x2f8cc0      1  \n",
       "0x31833a      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_X = pd.read_pickle(TRAIN_DATA_PATH)\n",
    "df_train_y = pd.read_pickle(TRAIN_LABEL_PATH)\n",
    "assert len(df_train_X) == len(df_train_y)\n",
    "df_train = pd.concat([df_train_X, df_train_y], axis=1)\n",
    "\n",
    "# numerical labels\n",
    "df_train['label'] = df_train['emotion'].map(lambda x: emotion2id[x])\n",
    "\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_pandas(df_train[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_datasets.save_to_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = Dataset.load_from_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1455563\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", 'tweet_id'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at data/cardiffnlp/twitter-roberta-base-emotion_tokenized_datasets/cache-874c557c48086f6c.arrow\n",
      "Loading cached shuffled indices for dataset at data/cardiffnlp/twitter-roberta-base-emotion_tokenized_datasets/cache-874c557c48086f6c.arrow\n"
     ]
    }
   ],
   "source": [
    "small_train_size = 50#0000\n",
    "small_eval_size = 10#000\n",
    "small_train_dataset = tokenized_datasets.shuffle(seed=42).select(range(small_train_size))\n",
    "small_eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(small_train_size, small_train_size + small_eval_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://towardsdatascience.com/adding-custom-layers-on-top-of-a-hugging-face-model-f1ccdfc257bd\n",
    "class CustomModel(torch.nn.Module):\n",
    "  def __init__(self, checkpoint, num_labels): \n",
    "    super(CustomModel,self).__init__() \n",
    "    self.num_labels = num_labels \n",
    "\n",
    "    #Load Model with given checkpoint and extract its body\n",
    "    self.model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
    "    self.dropout = torch.nn.Dropout(0.1) \n",
    "    self.classifier = torch.nn.Linear(768, num_labels) # load and initialize weights\n",
    "\n",
    "  def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "    #Extract outputs from the body\n",
    "    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    #Add custom layers\n",
    "    sequence_output = self.dropout(outputs[0]) #outputs[0]=last hidden state\n",
    "\n",
    "    logits = self.classifier(sequence_output[:,0,:].view(-1,768)) # calculate losses\n",
    "    \n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "      loss_fct = torch.nn.CrossEntropyLoss()\n",
    "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    \n",
    "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-emotion were not used when initializing RobertaModel: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emotion and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel(MODEL_NAME, NUM_LABELS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "num_training_steps = EPOCHS * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metric = evaluate.load(\"f1\")\n",
    "acu_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics():\n",
    "    f1_macro = f1_metric.compute(average='macro')['f1']\n",
    "    acu = acu_metric.compute()['accuracy']\n",
    "    return {'f1_macro': f1_macro, 'acu': acu}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af34088946594382b517022e42497b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f7384febc24b6e839705f4eff3cbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.16666666666666666, 'acu': 0.3}\n",
      "{'f1_macro': 0.16666666666666666, 'acu': 0.3}\n",
      "{'f1_macro': 0.16666666666666666, 'acu': 0.3}\n",
      "{'f1_macro': 0.16666666666666666, 'acu': 0.3}\n",
      "{'f1_macro': 0.16666666666666666, 'acu': 0.3}\n"
     ]
    }
   ],
   "source": [
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(EPOCHS * len(eval_dataloader)))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  model.train()\n",
    "  for batch in train_dataloader:\n",
    "      batch = {k: v.to(device) for k, v in batch.items()}\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "      lr_scheduler.step()\n",
    "      optimizer.zero_grad()\n",
    "      progress_bar_train.update(1)\n",
    "\n",
    "  model.eval()\n",
    "  for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    acu_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    progress_bar_eval.update(1)\n",
    "    \n",
    "  print(compute_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.275, 'acu': 0.4}\n"
     ]
    }
   ],
   "source": [
    "f1_metric = evaluate.load(\"f1\")\n",
    "acu_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    acu_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "print(compute_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x372160</th>\n",
       "      <td>568</td>\n",
       "      <td>2016-05-21 22:06:38</td>\n",
       "      <td>[baby, parenting, maternity, mumlife, Motherhood]</td>\n",
       "      <td>Got the tiredest #baby ever over here. Waking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x365823</th>\n",
       "      <td>859</td>\n",
       "      <td>2016-05-25 18:00:57</td>\n",
       "      <td>[]</td>\n",
       "      <td>The most high is always by myside,giving thnks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x23ea61</th>\n",
       "      <td>179</td>\n",
       "      <td>2016-04-03 16:50:10</td>\n",
       "      <td>[]</td>\n",
       "      <td>Okay okay I get that this is controversial and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2c5fc4</th>\n",
       "      <td>473</td>\n",
       "      <td>2015-08-10 07:25:31</td>\n",
       "      <td>[]</td>\n",
       "      <td>@mostlygeordie @StAustellBrew Prefer a proper ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x31f375</th>\n",
       "      <td>929</td>\n",
       "      <td>2017-02-09 21:07:25</td>\n",
       "      <td>[]</td>\n",
       "      <td>@paatriciaa43 But did you actually meet him th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _score           _crawldate  \\\n",
       "tweet_id                                \n",
       "0x372160     568  2016-05-21 22:06:38   \n",
       "0x365823     859  2016-05-25 18:00:57   \n",
       "0x23ea61     179  2016-04-03 16:50:10   \n",
       "0x2c5fc4     473  2015-08-10 07:25:31   \n",
       "0x31f375     929  2017-02-09 21:07:25   \n",
       "\n",
       "                                                   hashtags  \\\n",
       "tweet_id                                                      \n",
       "0x372160  [baby, parenting, maternity, mumlife, Motherhood]   \n",
       "0x365823                                                 []   \n",
       "0x23ea61                                                 []   \n",
       "0x2c5fc4                                                 []   \n",
       "0x31f375                                                 []   \n",
       "\n",
       "                                                       text  \n",
       "tweet_id                                                     \n",
       "0x372160  Got the tiredest #baby ever over here. Waking ...  \n",
       "0x365823  The most high is always by myside,giving thnks...  \n",
       "0x23ea61  Okay okay I get that this is controversial and...  \n",
       "0x2c5fc4  @mostlygeordie @StAustellBrew Prefer a proper ...  \n",
       "0x31f375  @paatriciaa43 But did you actually meet him th...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_pickle(TEST_DATA_PATH)\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[AAsking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 35/35 [00:19<00:00, 16.93it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|█████████▉| 411/412 [00:14<00:00, 28.85ba/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=['tweet_id', '_score', '_crawldate', 'hashtags'])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[1;32m      7\u001b[0m     batch \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m      8\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/dm/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/dm/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/dm/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/dm/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/dm/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py:2343\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m     \u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(\n\u001b[1;32m   2344\u001b[0m         key,\n\u001b[1;32m   2345\u001b[0m     )\n",
      "File \u001b[0;32m~/dm/venv/lib/python3.8/site-packages/datasets/arrow_dataset.py:2328\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, decoded\u001b[39m=\u001b[39mdecoded, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2327\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 2328\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2329\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[1;32m   2330\u001b[0m )\n\u001b[1;32m   2331\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/dm/venv/lib/python3.8/site-packages/datasets/formatting/formatting.py:516\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[39mreturn\u001b[39;00m python_formatter(pa_table, query_type\u001b[39m=\u001b[39mquery_type)\n\u001b[1;32m    515\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     pa_table_to_format \u001b[39m=\u001b[39m pa_table\u001b[39m.\u001b[39;49mdrop(col \u001b[39mfor\u001b[39;49;00m col \u001b[39min\u001b[39;49;00m pa_table\u001b[39m.\u001b[39;49mcolumn_names \u001b[39mif\u001b[39;49;00m col \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m format_columns)\n\u001b[1;32m    517\u001b[0m     formatted_output \u001b[39m=\u001b[39m formatter(pa_table_to_format, query_type\u001b[39m=\u001b[39mquery_type)\n\u001b[1;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m output_all_columns:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'id': df_test.index})\n",
    "df_result['label'] = np.zeros(len(df_result)) - 1\n",
    "\n",
    "idx = 0\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    inc = min(TEST_BATCH_SIZE, len(df_result) - idx)\n",
    "    df_result.loc[idx:idx+inc-1, 'label'] = predictions.cpu().numpy()\n",
    "    idx += inc\n",
    "\n",
    "# convert label to emotion\n",
    "df_result['emotion'] = df_result['label'].map(lambda x: id2emotion[x])\n",
    "\n",
    "df_result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[['id', 'emotion']].to_csv('submission/03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd18ad61a764f50ef87415555d6b20bbe826f43f65518458ad3ed025fdd4cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
