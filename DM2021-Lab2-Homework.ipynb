{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 黃俊瑋 \n",
    "\n",
    "Student ID: 108062308\n",
    "\n",
    "GitHub ID: [tangerine1202](https://github.com/tangerine1202/DM2022-Lab2-Homework)\n",
    "\n",
    "Kaggle name: [Chun Wei Huang](https://www.kaggle.com/tangerine1202)\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by [this link](https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd). The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "\n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the img folder of this repository and rerun the cell Student Information.\n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Part: Take Home Exercises\n",
    "\n",
    "- repo link: https://github.com/tangerine1202/DM2022-Lab2-Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Part: Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ident = pd.read_csv('data/data_identification.csv', index_col='tweet_id')\n",
    "# labels = pd.read_csv('data/emotion.csv', index_col='tweet_id')\n",
    "\n",
    "# print('train size', ident[ident['identification'] == 'train'].shape)\n",
    "# print('test  size', ident[ident['identification'] == 'test'].shape)\n",
    "\n",
    "# print(ident.head(3))\n",
    "# print(labels.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idxs = ident[ident['identification'] == 'train'].index\n",
    "# train_labels = labels.loc[train_idxs, 'emotion']\n",
    "\n",
    "# train_labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('labels distribution')\n",
    "# print(train_labels.value_counts())\n",
    "# sns.barplot(x=train_labels.value_counts().index, y=train_labels.value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('data/tweets_DM.json', lines=True)\n",
    "\n",
    "# # drop useless columns (only 1 unique value)\n",
    "# data = data.drop(columns=['_index', '_type'])\n",
    "# source = data['_source']\n",
    "\n",
    "# # parsing tweet\n",
    "# def parse_source(data):\n",
    "#     data = data['tweet']\n",
    "#     parsed_data = {}\n",
    "#     for key, value in data.items():\n",
    "#       parsed_data[key] = value\n",
    "#     return parsed_data\n",
    "# tweet = pd.DataFrame(source.map(parse_source).tolist())\n",
    "# data = pd.concat([data, tweet], axis=1)\n",
    "# data = data.drop(columns=['_source'])\n",
    "\n",
    "# data.set_index('tweet_id', inplace=True)\n",
    "\n",
    "# data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data.loc[train_idxs, :].sort_values(by='tweet_id')\n",
    "# test_data = data.loc[~data.index.isin(train_idxs), :].sort_values(by='tweet_id')\n",
    "# train_labels = train_labels.sort_index()\n",
    "\n",
    "# assert len(train_data) == len(train_labels)\n",
    "# assert np.all(train_data.index == train_labels.index)\n",
    "# print(len(data))\n",
    "# print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_pickle('data/train_data.pkl')\n",
    "# train_labels.to_pickle('data/train_labels.pkl')\n",
    "# test_data.to_pickle('data/test_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transferred model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 01:25:08.116497: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 01:25:08.479333: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-16 01:25:09.354479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-16 01:25:09.354633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:/home/alan/.cuda/lib64:/home/alan/.cuda/extras/CUPTI/lib64:\n",
      "2022-11-16 01:25:09.354645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_metric\n",
    "import evaluate\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import get_scheduler\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "TRAIN_DATA_PATH = 'data/train_data.pkl'\n",
    "TRAIN_LABEL_PATH = 'data/train_labels.pkl'\n",
    "TEST_DATA_PATH = 'data/test_data.pkl'\n",
    "CHECKPOINTS_PATH = 'checkpoints/'\n",
    "EMOTION_NAMES = ['joy', 'anticipation', 'trust' , 'sadness' , 'disgust' , 'fear' , 'surprise', 'anger']\n",
    "INPUT_COLUMNS = ['text', 'label', *[f'{emo}_ratio' for emo in EMOTION_NAMES]]\n",
    "\n",
    "# constants\n",
    "MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "NUM_LABELS = 8\n",
    "CHECKPOINTS_SIZE = 1000\n",
    "\n",
    "# hyper-parameters\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "TRAIN_SIZE = 100000\n",
    "EVAL_SIZE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion2id = {emotion: i for i, emotion in enumerate(EMOTION_NAMES)}\n",
    "id2emotion = {i: emotion for i, emotion in enumerate(EMOTION_NAMES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>joy_ratio</th>\n",
       "      <th>anticipation_ratio</th>\n",
       "      <th>trust_ratio</th>\n",
       "      <th>sadness_ratio</th>\n",
       "      <th>disgust_ratio</th>\n",
       "      <th>fear_ratio</th>\n",
       "      <th>surprise_ratio</th>\n",
       "      <th>anger_ratio</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x344305</th>\n",
       "      <td>239</td>\n",
       "      <td>2017-08-10 20:33:04</td>\n",
       "      <td>[SECP]</td>\n",
       "      <td>Playing with national institutions is like pla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>disgust</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x24a9c6</th>\n",
       "      <td>269</td>\n",
       "      <td>2016-08-24 02:10:48</td>\n",
       "      <td>[BillOBrien, Texans, TNF]</td>\n",
       "      <td>Anyone consider that #BillOBrien may just be a...</td>\n",
       "      <td>0.247719</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.108421</td>\n",
       "      <td>0.190877</td>\n",
       "      <td>0.236140</td>\n",
       "      <td>0.023860</td>\n",
       "      <td>0.030526</td>\n",
       "      <td>0.039649</td>\n",
       "      <td>disgust</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1f9f26</th>\n",
       "      <td>205</td>\n",
       "      <td>2015-09-18 12:16:57</td>\n",
       "      <td>[]</td>\n",
       "      <td>My brother just said \"this kid I used to be fr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>trust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1e9c2b</th>\n",
       "      <td>420</td>\n",
       "      <td>2016-10-22 14:23:13</td>\n",
       "      <td>[Jesus, TheWalkingDead]</td>\n",
       "      <td>Damnit, #Jesus, stop being so...like Jesus!  T...</td>\n",
       "      <td>0.053433</td>\n",
       "      <td>0.680370</td>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.102495</td>\n",
       "      <td>0.019505</td>\n",
       "      <td>0.037247</td>\n",
       "      <td>0.013209</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x26bcdb</th>\n",
       "      <td>47</td>\n",
       "      <td>2015-01-24 02:07:17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Love changes lives. &lt;LH&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _score           _crawldate                   hashtags  \\\n",
       "tweet_id                                                           \n",
       "0x344305     239  2017-08-10 20:33:04                     [SECP]   \n",
       "0x24a9c6     269  2016-08-24 02:10:48  [BillOBrien, Texans, TNF]   \n",
       "0x1f9f26     205  2015-09-18 12:16:57                         []   \n",
       "0x1e9c2b     420  2016-10-22 14:23:13    [Jesus, TheWalkingDead]   \n",
       "0x26bcdb      47  2015-01-24 02:07:17                         []   \n",
       "\n",
       "                                                       text  joy_ratio  \\\n",
       "tweet_id                                                                 \n",
       "0x344305  Playing with national institutions is like pla...   0.000000   \n",
       "0x24a9c6  Anyone consider that #BillOBrien may just be a...   0.247719   \n",
       "0x1f9f26  My brother just said \"this kid I used to be fr...   0.000000   \n",
       "0x1e9c2b  Damnit, #Jesus, stop being so...like Jesus!  T...   0.053433   \n",
       "0x26bcdb                           Love changes lives. <LH>   0.000000   \n",
       "\n",
       "          anticipation_ratio  trust_ratio  sadness_ratio  disgust_ratio  \\\n",
       "tweet_id                                                                  \n",
       "0x344305            0.000000     0.000000       0.000000       0.000000   \n",
       "0x24a9c6            0.122807     0.108421       0.190877       0.236140   \n",
       "0x1f9f26            0.000000     0.000000       0.000000       0.000000   \n",
       "0x1e9c2b            0.680370     0.021627       0.072114       0.102495   \n",
       "0x26bcdb            0.000000     0.000000       0.000000       0.000000   \n",
       "\n",
       "          fear_ratio  surprise_ratio  anger_ratio       emotion  label  \n",
       "tweet_id                                                                \n",
       "0x344305    0.000000        0.000000     0.000000       disgust      4  \n",
       "0x24a9c6    0.023860        0.030526     0.039649       disgust      4  \n",
       "0x1f9f26    0.000000        0.000000     0.000000         trust      2  \n",
       "0x1e9c2b    0.019505        0.037247     0.013209  anticipation      1  \n",
       "0x26bcdb    0.000000        0.000000     0.000000           joy      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_X = pd.read_pickle(TRAIN_DATA_PATH)\n",
    "df_train_y = pd.read_pickle(TRAIN_LABEL_PATH)\n",
    "assert len(df_train_X) == len(df_train_y)\n",
    "df_train = pd.concat([df_train_X, df_train_y], axis=1)\n",
    "\n",
    "# numerical labels\n",
    "df_train['label'] = df_train['emotion'].map(lambda x: emotion2id[x])\n",
    "\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_pandas(df_train[INPUT_COLUMNS]])\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_datasets.save_to_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = Dataset.load_from_disk(f'data/{MODEL_NAME}_tokenized_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'joy_ratio', 'anticipation_ratio', 'trust_ratio', 'sadness_ratio', 'disgust_ratio', 'fear_ratio', 'surprise_ratio', 'anger_ratio', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1455563\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", 'tweet_id'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at data/cardiffnlp/twitter-roberta-base-sentiment-latest_tokenized_datasets/cache-6aa2f57568fda59c.arrow\n",
      "Loading cached shuffled indices for dataset at data/cardiffnlp/twitter-roberta-base-sentiment-latest_tokenized_datasets/cache-6aa2f57568fda59c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 100000\n",
      "eval size: 2000\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_datasets.shuffle(seed=42).select(range(TRAIN_SIZE))\n",
    "small_eval_dataset = tokenized_datasets.shuffle(seed=42).select(range(TRAIN_SIZE, TRAIN_SIZE + EVAL_SIZE))\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "\n",
    "print(f'training size: {len(small_train_dataset)}')\n",
    "print(f'eval size: {len(small_eval_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://towardsdatascience.com/adding-custom-layers-on-top-of-a-hugging-face-model-f1ccdfc257bd\n",
    "class CustomModel(torch.nn.Module):\n",
    "  def __init__(self, checkpoint, num_labels): \n",
    "    super(CustomModel,self).__init__() \n",
    "    self.num_labels = num_labels \n",
    "\n",
    "    #Load Model with given checkpoint and extract its body\n",
    "    self.model = AutoModel.from_pretrained(checkpoint,config=AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True))\n",
    "    self.seq_dropout = torch.nn.Dropout(0.3) \n",
    "    self.features_dropout = torch.nn.Dropout(0.0)\n",
    "    self.classifier = torch.nn.Linear(768 + NUM_LABELS, num_labels) # load and initialize weights\n",
    "\n",
    "  def forward(self, \n",
    "    input_ids=None, attention_mask=None, labels=None,\n",
    "    joy_ratio=None, anticipation_ratio=None, trust_ratio=None, sadness_ratio=None, disgust_ratio=None, fear_ratio=None, surprise_ratio=None, anger_ratio=None\n",
    "  ):\n",
    "    # Extract outputs from the body\n",
    "    # pretrained_outputs[0]=last hidden state\n",
    "    pretrained_outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    seq_outputs = self.seq_dropout(pretrained_outputs[0])[:, 0, :].view(-1, 768) # seq shape torch.Size([16, 768])\n",
    "\n",
    "    # Add emotion ratios\n",
    "    emo_ratio_outputs = torch.stack([joy_ratio, anticipation_ratio, trust_ratio, sadness_ratio, disgust_ratio, fear_ratio, surprise_ratio, anger_ratio], dim=1)\n",
    "    features_outputs = self.features_dropout(emo_ratio_outputs) # emo_ratio shape torch.Size([16, 8])\n",
    "\n",
    "    # Concatenate\n",
    "    outputs = torch.cat((seq_outputs, features_outputs), dim=1)\n",
    "    logits = self.classifier(outputs) # calculate losses\n",
    "    \n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "      loss_fct = torch.nn.CrossEntropyLoss()\n",
    "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    \n",
    "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=pretrained_outputs.hidden_states ,attentions=pretrained_outputs.attentions)\n",
    "  \n",
    "  def save_checkpoint(self, model_name, steps):\n",
    "    torch.save(self.state_dict(), f'{CHECKPOINTS_PATH}{model_name}_{steps}.pt')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiate new model\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(f'model/{MODEL_NAME}-custom-{TRAIN_SIZE}') and input('Use pretrain model? (y/n)') == 'y':\n",
    "  model = torch.load(f'model/{MODEL_NAME}-custom-{TRAIN_SIZE}').to(device)\n",
    "  print('Using pretrained model')\n",
    "else:\n",
    "  model = CustomModel(MODEL_NAME, NUM_LABELS).to(device)\n",
    "  print('Instantiate new model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "num_training_steps = EPOCHS * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=EVAL_SIZE, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metric = evaluate.load(\"f1\")\n",
    "acu_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics():\n",
    "    f1_macro = f1_metric.compute(average='macro')['f1']\n",
    "    acu = acu_metric.compute()['accuracy']\n",
    "    return {'f1_macro': f1_macro, 'acu': acu}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb8585a48fa43ea8f181bd9adb578db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87877657d604a97b069b360a1393f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000 loss: 1.3972753407359124\n",
      "{'f1_macro': 0.44788661748638825, 'acu': 0.5555}\n",
      "step 2000 loss: 1.1707748259902\n",
      "{'f1_macro': 0.5020814179602406, 'acu': 0.5915}\n",
      "step 3000 loss: 1.1446234025359154\n",
      "{'f1_macro': 0.5024441902222214, 'acu': 0.584}\n",
      "step 4000 loss: 1.0156625973284243\n",
      "{'f1_macro': 0.5149974739328864, 'acu': 0.6035}\n",
      "step 5000 loss: 0.9935094375014305\n",
      "{'f1_macro': 0.5281572075712743, 'acu': 0.608}\n",
      "step 6000 loss: 0.9503588571846485\n",
      "{'f1_macro': 0.5257820254897689, 'acu': 0.6145}\n",
      "step 7000 loss: 0.7806139044761657\n",
      "{'f1_macro': 0.5372428319237448, 'acu': 0.6225}\n",
      "step 8000 loss: 0.7203718647062779\n",
      "{'f1_macro': 0.5577827970368987, 'acu': 0.635}\n",
      "step 9000 loss: 0.6810925497114658\n",
      "{'f1_macro': 0.5506582006599503, 'acu': 0.6295}\n"
     ]
    }
   ],
   "source": [
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(EPOCHS * len(eval_dataloader)))\n",
    "\n",
    "best_f1 = 0\n",
    "steps = 0\n",
    "cumulative_loss = 0\n",
    "for epoch in range(EPOCHS):\n",
    "  model.train()\n",
    "  for batch in train_dataloader:\n",
    "      batch = {k: v.to(device) for k, v in batch.items()}\n",
    "      outputs = model(**batch)\n",
    "      loss = outputs.loss\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "      lr_scheduler.step()\n",
    "      optimizer.zero_grad()\n",
    "      progress_bar_train.update(1)\n",
    "\n",
    "      cumulative_loss += loss.item()\n",
    "      steps += 1\n",
    "\n",
    "      if steps % CHECKPOINTS_SIZE == 0:\n",
    "        print(f'step {steps} loss: {cumulative_loss / CHECKPOINTS_SIZE}')\n",
    "        cumulative_loss = 0\n",
    "        model.save_checkpoint(MODEL_NAME, steps)\n",
    "\n",
    "        model.eval()\n",
    "        for batch in eval_dataloader:\n",
    "          batch = {k: v.to(device) for k, v in batch.items()}\n",
    "          with torch.no_grad():\n",
    "              outputs = model(**batch)\n",
    "\n",
    "          logits = outputs.logits\n",
    "          predictions = torch.argmax(logits, dim=-1)\n",
    "          f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "          acu_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "          progress_bar_eval.update(1)\n",
    "          \n",
    "        metrics = compute_metrics()\n",
    "        print(metrics)\n",
    "\n",
    "        if metrics['f1_macro'] < best_f1 - 0.2:\n",
    "          print(f'Early stopping at step {steps}, f1 drop {metrics[\"f1_macro\"] - best_f1} from {best_f1} to {metrics[\"f1_macro\"]}')\n",
    "          break\n",
    "        best_f1 = max(best_f1, metrics['f1_macro'])\n",
    "\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load checkpoints\n",
    "model.load_state_dict(torch.load(f'{CHECKPOINTS_PATH}{MODEL_NAME}_{8000}.pt'))\n",
    "# save\n",
    "# torch.save(model, f'model/{MODEL_NAME}-custom-{TRAIN_SIZE}x{EPOCHS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/alan/dm/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2322: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_macro': 0.5577827970368987, 'acu': 0.635}\n"
     ]
    }
   ],
   "source": [
    "f1_metric = evaluate.load(\"f1\")\n",
    "acu_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    acu_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "print(compute_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "TEST_INPUT_COLUMNS = INPUT_COLUMNS.copy()\n",
    "if 'label' in TEST_INPUT_COLUMNS:\n",
    "  TEST_INPUT_COLUMNS.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>joy_ratio</th>\n",
       "      <th>anticipation_ratio</th>\n",
       "      <th>trust_ratio</th>\n",
       "      <th>sadness_ratio</th>\n",
       "      <th>disgust_ratio</th>\n",
       "      <th>fear_ratio</th>\n",
       "      <th>surprise_ratio</th>\n",
       "      <th>anger_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x30d8de</th>\n",
       "      <td>53</td>\n",
       "      <td>2016-12-25 01:42:11</td>\n",
       "      <td>[]</td>\n",
       "      <td>I lost one of my earrings today while at the c...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2e8a3b</th>\n",
       "      <td>940</td>\n",
       "      <td>2015-07-13 02:01:09</td>\n",
       "      <td>[stillhungry]</td>\n",
       "      <td>Asked for a hash brown at German McD’s, I thou...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2bfc9a</th>\n",
       "      <td>558</td>\n",
       "      <td>2017-10-14 14:57:45</td>\n",
       "      <td>[tired, trauma, mentalhealth]</td>\n",
       "      <td>I survived today. my mind didn’t dissociate. I...</td>\n",
       "      <td>0.200981</td>\n",
       "      <td>0.131773</td>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.252622</td>\n",
       "      <td>0.076753</td>\n",
       "      <td>0.066048</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>0.09989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x315d94</th>\n",
       "      <td>129</td>\n",
       "      <td>2016-10-09 08:32:01</td>\n",
       "      <td>[]</td>\n",
       "      <td>as much as i love travelling nothing feels bet...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x260321</th>\n",
       "      <td>732</td>\n",
       "      <td>2015-02-03 15:17:43</td>\n",
       "      <td>[anotherfutureSpartan]</td>\n",
       "      <td>@BenBoudro congrats to you and your family.  #...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _score           _crawldate                       hashtags  \\\n",
       "tweet_id                                                               \n",
       "0x30d8de      53  2016-12-25 01:42:11                             []   \n",
       "0x2e8a3b     940  2015-07-13 02:01:09                  [stillhungry]   \n",
       "0x2bfc9a     558  2017-10-14 14:57:45  [tired, trauma, mentalhealth]   \n",
       "0x315d94     129  2016-10-09 08:32:01                             []   \n",
       "0x260321     732  2015-02-03 15:17:43         [anotherfutureSpartan]   \n",
       "\n",
       "                                                       text  joy_ratio  \\\n",
       "tweet_id                                                                 \n",
       "0x30d8de  I lost one of my earrings today while at the c...   0.000000   \n",
       "0x2e8a3b  Asked for a hash brown at German McD’s, I thou...   0.000000   \n",
       "0x2bfc9a  I survived today. my mind didn’t dissociate. I...   0.200981   \n",
       "0x315d94  as much as i love travelling nothing feels bet...   0.000000   \n",
       "0x260321  @BenBoudro congrats to you and your family.  #...   0.000000   \n",
       "\n",
       "          anticipation_ratio  trust_ratio  sadness_ratio  disgust_ratio  \\\n",
       "tweet_id                                                                  \n",
       "0x30d8de            0.000000     0.000000       0.000000       0.000000   \n",
       "0x2e8a3b            0.000000     0.000000       0.000000       0.000000   \n",
       "0x2bfc9a            0.131773     0.151721       0.252622       0.076753   \n",
       "0x315d94            0.000000     0.000000       0.000000       0.000000   \n",
       "0x260321            0.000000     0.000000       0.000000       0.000000   \n",
       "\n",
       "          fear_ratio  surprise_ratio  anger_ratio  \n",
       "tweet_id                                           \n",
       "0x30d8de    0.000000        0.000000      0.00000  \n",
       "0x2e8a3b    0.000000        0.000000      0.00000  \n",
       "0x2bfc9a    0.066048        0.020213      0.09989  \n",
       "0x315d94    0.000000        0.000000      0.00000  \n",
       "0x260321    0.000000        0.000000      0.00000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_pickle(TEST_DATA_PATH)\n",
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321c90960a0344cfb0ecad6a2fd42a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['joy_ratio', 'anticipation_ratio', 'trust_ratio', 'sadness_ratio', 'disgust_ratio', 'fear_ratio', 'surprise_ratio', 'anger_ratio', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 411972\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(df_test[TEST_INPUT_COLUMNS])\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.remove_columns([\"text\", 'tweet_id'])\n",
    "test_dataset.set_format(type='torch')\n",
    "model.to(device)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c773f093a3249dba67a1319e75b7c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'id': df_test.index})\n",
    "df_result['label'] = np.zeros(len(df_result)) - 1\n",
    "\n",
    "progress_bar_test = tqdm(range(len(test_dataloader)))\n",
    "\n",
    "idx = 0\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    inc = min(TEST_BATCH_SIZE, len(df_result) - idx)\n",
    "    df_result.loc[idx:idx+inc-1, 'label'] = predictions.cpu().numpy()\n",
    "    idx += inc\n",
    "    progress_bar_test.update(1)\n",
    "\n",
    "# convert label to emotion\n",
    "df_result['emotion'] = df_result['label'].map(lambda x: id2emotion[x])\n",
    "\n",
    "df_result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission/cardiffnlp/twitter-roberta-base-sentiment-latest-custom-500000x3.csv\n"
     ]
    }
   ],
   "source": [
    "saved_path = f'submission/{MODEL_NAME}-custom-{TRAIN_SIZE}x{EPOCHS}.csv'\n",
    "df_result[['id', 'emotion']].to_csv(saved_path, index=False)\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd18ad61a764f50ef87415555d6b20bbe826f43f65518458ad3ed025fdd4cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
